{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3759d02-de65-4632-8a32-5261530d9c35",
   "metadata": {},
   "source": [
    "# E2E recsys with matching engine and TFRS\n",
    "\n",
    "\n",
    "Simple example, goal being:\n",
    "\n",
    "    1) Train a Two-Tower model using movielens data\n",
    "    \n",
    "    2) Deploy the query model endpoint\n",
    "    \n",
    "    3) Save movie embeddings to json, for use in matching engine\n",
    "    \n",
    "    \n",
    "#### Note on VPC Pairing - insturctions for in-notebook pairing [here](https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/matching_engine/sdk_matching_engine_for_indexing.ipynb)\n",
    "    \n",
    "First we will create a user-managed notebook behind the already created peered VPC network used for Matching Engine. Select tensorflow enterprise 2.6 with a T4 GPU\n",
    "\n",
    "\n",
    "![](./create-workbench.png)\n",
    "\n",
    "\n",
    "##### Be sure to create the notebook in the peered network\n",
    "\n",
    "\n",
    "![](./network-create.png)\n",
    "\n",
    "    \n",
    "The next notebook will connect matching engine with the query endpoint for a simple recommender system\n",
    "\n",
    "Run the below pip install one time to install tensorflow-recommenders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1643d1c-9361-4880-8d43-d363f68da0c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !echo Y | pip uninstall tensorflow\n",
    "!pip install tensorflow-recommenders==0.6.0 --user"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dfd3e5a-545d-4d7b-87de-cb6422d08285",
   "metadata": {},
   "source": [
    "### Important - restart the kernel after installing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54877358-e37c-4404-9ab2-ca7360f9ef49",
   "metadata": {},
   "source": [
    "# Train a 2 tower model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d39132d-f08e-4d2c-be54-75e5067e8b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Text\n",
    "\n",
    "import json\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow_recommenders as tfrs\n",
    "\n",
    "# disable INFO and DEBUG logging everywhere\n",
    "import logging\n",
    "\n",
    "from google.cloud import aiplatform_v1beta1 #needed for matching engine calls\n",
    "from google.protobuf import struct_pb2\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "DIMENSIONS = 64 # this is how large the embedding dimensions get\n",
    "\n",
    "\n",
    "# Ratings data.\n",
    "ratings = tfds.load('movielens/100k-ratings', split=\"train\")\n",
    "# Features of all the available movies.\n",
    "movies = tfds.load('movielens/100k-movies', split=\"train\")\n",
    "\n",
    "# Select the basic features.\n",
    "ratings = ratings.map(lambda x: {\n",
    "    \"movie_id\": tf.strings.to_number(x[\"movie_id\"]),\n",
    "    \"user_id\": tf.strings.to_number(x[\"user_id\"])\n",
    "})\n",
    "movies = movies.map(lambda x: tf.strings.to_number(x[\"movie_id\"]))\n",
    "\n",
    "# Build a model.\n",
    "class Model(tfrs.Model):\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        # Set up user representation.\n",
    "        self.user_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(\n",
    "            input_dim=2000, output_dim=DIMENSIONS),\n",
    "            ])\n",
    "        # Set up movie representation.\n",
    "        self.item_model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Embedding(\n",
    "            input_dim=2000, output_dim=DIMENSIONS),\n",
    "        ])\n",
    "        # Set up a retrieval task and evaluation metrics over the\n",
    "        # entire dataset of candidates.\n",
    "        self.task = tfrs.tasks.Retrieval(\n",
    "            metrics=tfrs.metrics.FactorizedTopK(\n",
    "                candidates=movies.batch(128).map(self.item_model)\n",
    "            )\n",
    "        )\n",
    "\n",
    "    def compute_loss(self, features: Dict[Text, tf.Tensor], training=False) -> tf.Tensor:\n",
    "\n",
    "        user_embeddings = self.user_model(features[\"user_id\"])\n",
    "        movie_embeddings = self.item_model(features[\"movie_id\"])\n",
    "\n",
    "        return self.task(user_embeddings, movie_embeddings)\n",
    "\n",
    "\n",
    "model = Model()\n",
    "model.compile(optimizer=tf.keras.optimizers.Adagrad(0.5))\n",
    "\n",
    "# Randomly shuffle data and split between train and test.\n",
    "tf.random.set_seed(42)\n",
    "shuffled = ratings.shuffle(100_000, seed=42, reshuffle_each_iteration=False)\n",
    "\n",
    "train = shuffled.take(80_000)\n",
    "test = shuffled.skip(80_000).take(20_000)\n",
    "\n",
    "# Train.\n",
    "model.fit(train.batch(1024), epochs=5)\n",
    "\n",
    "# Evaluate.\n",
    "model.evaluate(test.batch(1024), return_dict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fbaec34-8a04-404d-aaa7-e8fe0eb82797",
   "metadata": {},
   "source": [
    "### Set your variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12134d47-284d-4e55-8476-df3db335de48",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a bucket one-time\n",
    "# ! gsutil mb -l us-central1 gs://end-to-end-two-tower-wayfair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "367695ef-4330-4dee-a296-94ac68850744",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "PROJECT = 'wayfair-361917' #set to your own\n",
    "NETWORK_NAME = 'matching-engine-vpc' #same as VPC peered network\n",
    "\n",
    "### Create a bucket to store our embeddings and models\n",
    "BUCKET = 'gs://end-to-end-two-tower-wayfair' # TODO - change for each user\n",
    "EMBEDDINGS = os.path.join(BUCKET, 'embeddings')\n",
    "QUERY_MODEL = os.path.join(BUCKET, 'query_model')\n",
    "REGION = 'us-central1'\n",
    "\n",
    "## Gets an auth token with the Parent variable\n",
    "PROJECT_ID = PROJECT\n",
    "AUTH_TOKEN = !gcloud auth print-access-token\n",
    "PROJECT_NUMBER = ! gcloud projects list --filter=\"$PROJECT_ID\" --format=\"value(PROJECT_NUMBER)\"\n",
    "PROJECT_NUMBER = PROJECT_NUMBER[0]\n",
    "\n",
    "\n",
    "PARENT = \"projects/{}/locations/{}\".format(PROJECT_ID, REGION)\n",
    "PARENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c97eedb-0d0d-4eea-a90f-ed3fd162b92f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run one time to create your bucket\n",
    "# !gsutil mb -l $REGION $BUCKET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c40d03-6ee1-4e50-8742-1455bcfaf632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the query/user model\n",
    "\n",
    "model.user_model.save(QUERY_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11ac9bbe-d100-4db9-aa6a-97889b540ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure it saved\n",
    "!gsutil ls $QUERY_MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14604762-46fd-413b-97fe-dd3c3e4ce182",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import aiplatform\n",
    "\n",
    "model_gcp = aiplatform.Model.upload(\n",
    "        display_name=\"Movielens User Query Model\",\n",
    "        artifact_uri=QUERY_MODEL,\n",
    "        serving_container_image_uri='us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-6:latest',\n",
    "        description=\"Top of the query tower, meant to return an embedding for each user instance\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f87b1b-5686-4640-bac9-aa2b4d836417",
   "metadata": {},
   "outputs": [],
   "source": [
    "#validate the model type output\n",
    "model_gcp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3f621f-60a6-47d3-b7a3-49082f6c9aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24a05ae9-6deb-4db3-91f2-41676067f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = aiplatform.Endpoint.create(\n",
    "    display_name=\"Movielens Model Endpoint\",\n",
    "    project=PROJECT,\n",
    "    location=REGION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ddcf4a-c5a2-4593-9895-93b811081a38",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment = model_gcp.deploy(\n",
    "    endpoint=endpoint,\n",
    "    deployed_model_display_name=\"Movielens User Query Model\",\n",
    "    machine_type=\"n1-standard-4\",\n",
    "    min_replica_count=1,\n",
    "    max_replica_count=2,\n",
    "    accelerator_type=None,\n",
    "    accelerator_count=0,\n",
    "    sync=False,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ed84db-5c12-44fe-ad93-580b9bf7a736",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fecb85c3-18b9-470d-9880-bd91b3d22564",
   "metadata": {},
   "source": [
    "## Save the embeddings for the movie dataset\n",
    "\n",
    "### Write embeddings to local storage\n",
    "Following this format for Matching Engine\n",
    "https://github.com/GoogleCloudPlatform/vertex-ai-samples/blob/main/notebooks/community/matching_engine/sdk_matching_engine_for_indexing.ipynb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c49bab-4aa0-484c-84cf-ceebe88c5b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_embs = movies.batch(1000).map(lambda x: [x, model.item_model(x)]).unbatch() #process 1000 at a time then flatten it back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eed5978-7ee0-48e1-a98a-08119a52989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write to local disk\n",
    "with open(\"movie_embeddings.json\", 'w') as f:\n",
    "    for movie_id, movie_emb in movie_embs:\n",
    "        # print(movie_id.numpy(), movie_emb.numpy())\n",
    "        f.write('{\"id\":\"' + str(movie_id.numpy()) + '\",\"embedding\":[' + \",\".join(str(x) for x in list(movie_emb.numpy())) + ']}')\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71ccbe63-9f63-4da0-8314-30244c7a8df1",
   "metadata": {},
   "source": [
    "You should now see .json data as required by matching engine\n",
    "![](jsonl.png)\n",
    "\n",
    "### Upload the data to GCS\n",
    "Only remove if you have issues uploading the json file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd0c7011-dbf2-4f73-adcc-89aff7ecb7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp movie_embeddings.json $EMBEDDINGS/movie_embeddings.json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee1af7d-d6db-4bd6-91d6-f8343700ea94",
   "metadata": {},
   "source": [
    "# Next we will deploy our movie inidicies. With Matching Engine\n",
    "* Create an index (from the `json` files)\n",
    "* Create and endpoint\n",
    "* Deploy the index to the endpoint so you can perform vector search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c678c72-3604-4d32-b1f9-7639066932e0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "api_endpoint_me = \"{}-aiplatform.googleapis.com\".format(REGION)\n",
    "\n",
    "index_client = aiplatform_v1beta1.IndexServiceClient(\n",
    "    client_options=dict(api_endpoint=api_endpoint_me)\n",
    ")\n",
    "\n",
    "\n",
    "DISPLAY_NAME = f\"Movielens Movie: {DIMENSIONS} DIMENSIONS\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49483180-e16a-48ac-9954-557dc2718144",
   "metadata": {},
   "source": [
    "Set the Nearest Neighbor Options\n",
    "\n",
    "See here for tips on [tuning the index](https://cloud.google.com/vertex-ai/docs/matching-engine/using-matching-engine#tuning_the_index)\n",
    "\n",
    "Other best practices from our PM team:\n",
    "```\n",
    "Start from leafNodesToSearchPercent=5 and approximateNeighborsCount=10 * k\n",
    "\n",
    "use default values for others.\n",
    "\n",
    "measure performance and recall and change those 2 parameters accordingly.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ed453f-d1de-4a53-af86-ebd74785d33b",
   "metadata": {},
   "outputs": [],
   "source": [
    "treeAhConfig = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"leafNodeEmbeddingCount\": struct_pb2.Value(number_value=20),\n",
    "        \"leafNodesToSearchPercent\": struct_pb2.Value(number_value=7),\n",
    "    }\n",
    ")\n",
    "\n",
    "algorithmConfig = struct_pb2.Struct(\n",
    "    fields={\"treeAhConfig\": struct_pb2.Value(struct_value=treeAhConfig)}\n",
    ")\n",
    "\n",
    "config = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"dimensions\": struct_pb2.Value(number_value=DIMENSIONS),\n",
    "        \"approximateNeighborsCount\": struct_pb2.Value(number_value=10),\n",
    "        \"distanceMeasureType\": struct_pb2.Value(string_value=\"DOT_PRODUCT_DISTANCE\"),\n",
    "        \"algorithmConfig\": struct_pb2.Value(struct_value=algorithmConfig),\n",
    "    }\n",
    ")\n",
    "\n",
    "metadata = struct_pb2.Struct(\n",
    "    fields={\n",
    "        \"config\": struct_pb2.Value(struct_value=config),\n",
    "        \"contentsDeltaUri\": struct_pb2.Value(string_value=EMBEDDINGS),\n",
    "    }\n",
    ")\n",
    "\n",
    "ann_index = {\n",
    "    \"display_name\": DISPLAY_NAME,\n",
    "    \"description\": f\"Movielens {DIMENSIONS}\",\n",
    "    \"metadata\": struct_pb2.Value(struct_value=metadata),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a429a9e9-85b4-420d-a6ac-200e45cb61df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index = index_client.create_index(parent=PARENT, index=ann_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c66dcd9-32e7-468b-97f2-8acf9ed3c1bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Poll the operation until it's done successfullly.\n",
    "# This will take ~40 min.\n",
    "import time \n",
    "\n",
    "while True:\n",
    "    if ann_index.done():\n",
    "        break\n",
    "    print(\"Poll the operation to create index...\")\n",
    "    time.sleep(60)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea507c13-1434-4e7c-88ae-d8fd0e6e7665",
   "metadata": {},
   "source": [
    "## Note on the advantages of the algorithm\n",
    "\n",
    "[link](https://arxiv.org/pdf/1908.10396.pdf)\n",
    "\n",
    "```However, it is easy to see that not all pairs of (x, q) are equally important. The approximation error on the pairs which have a high inner product is far more important since they are likely to be among the top ranked pairs and can greatly affect the search result, while for the pairs whose inner product is low the approximation error matters much less. In other words, for a given datapoint x, we should quantize it with a bigger focus on its error with those queries which have high inner product with x. See Figure 1 for the illustration.```\n",
    "\n",
    "\n",
    "![](./algo.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5016aed4-0ca8-4a08-86f4-aa86f5ca2a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355d7d95-6067-43fc-afc9-b9a75510d6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57af30e4-6572-4843-8539-f9801bf89609",
   "metadata": {},
   "source": [
    "### Save the name of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34c7bcbe-6bc5-4740-ae7d-a7bc40389ae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME = ann_index.result().name\n",
    "INDEX_RESOURCE_NAME"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bab2c7-c7ca-45d6-ae49-00903d13d0a7",
   "metadata": {},
   "source": [
    "Debugging tool in case you run into issues. Example usage below.\n",
    "`!gcloud beta ai operations describe 4122851463774863360 --index=7253099976438317056 --project=$PROJECT`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ae2c000-792b-4766-9562-fddf93387308",
   "metadata": {},
   "source": [
    "## Create Index Endpoint and Deploy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a02349-03dd-4e77-8935-59aa7ca7da5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_NUMBER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "596eea7a-c339-45ee-9443-e4777e073bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "VPC_NETWORK_NAME = \"projects/{}/global/networks/{}\".format(PROJECT_NUMBER, NETWORK_NAME)\n",
    "VPC_NETWORK_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f6267d-e920-475a-899e-25811f4eefbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint = {\n",
    "    \"display_name\": \"index_endpoint_for_demo\",\n",
    "    \"network\": VPC_NETWORK_NAME,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3959ed5b-8122-4840-8efc-6efed67f74d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_client = aiplatform_v1beta1.IndexEndpointServiceClient(\n",
    "    client_options=dict(api_endpoint=api_endpoint_me)\n",
    ")\n",
    "\n",
    "ann_index_en = index_endpoint_client.create_index_endpoint(\n",
    "    parent=PARENT, index_endpoint=index_endpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d70e1ef-2abd-43b1-827b-b884f34624df",
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_index_en.result()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36a5661-9fd5-4b9a-9922-6aae5b68af00",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_ENDPOINT_NAME = ann_index_en.result().name\n",
    "INDEX_ENDPOINT_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beaf193d-bd0e-40be-80fa-dd4dbe641cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYED_INDEX_ID = 'movielens_deployed2'\n",
    "\n",
    "deploy_ann_index = {\n",
    "    \"id\": DEPLOYED_INDEX_ID,\n",
    "    \"display_name\": DEPLOYED_INDEX_ID,\n",
    "    \"index\": INDEX_RESOURCE_NAME,\n",
    "}\n",
    "r = index_endpoint_client.deploy_index(\n",
    "    index_endpoint=INDEX_ENDPOINT_NAME, deployed_index=deploy_ann_index\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717b31a2-d4d9-40c5-9d49-224b120c4819",
   "metadata": {},
   "outputs": [],
   "source": [
    "r.result()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bdc5328-aee5-4042-ba33-95604e74e196",
   "metadata": {},
   "source": [
    "# Connect Matching Engine and The User Model Into a Recommendation System\n",
    "\n",
    "This will bring it all together by incorporating the prediction endpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3663265-9097-4ab5-8ed5-b6065ceecec6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# establish index_endpoint -IMPORTANT for constructing already created endpoints/indicies/etc...\n",
    "ME_index_endpoint = aiplatform.MatchingEngineIndexEndpoint(INDEX_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78b86481-e4fa-4c9c-b37d-8ab691f08574",
   "metadata": {},
   "outputs": [],
   "source": [
    "USER = 627.0 #pick anyone 0-100k to see watch history and recommendations\n",
    "NUM_NEIGH=3\n",
    "\n",
    "emb_627 = endpoint.predict([[USER]]) #prediction from the saved model\n",
    "emb_627 = emb_627.predictions[0]\n",
    "emb_627 # we should get our user xxx embedding @ dim len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a974e272-28e6-4b9f-bf75-62bd41ce50bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ME_index_endpoint.match(queries=emb_627, deployed_index_id=DEPLOYED_INDEX_ID, num_neighbors=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62f276c5-2899-4623-959c-9fadeda97cba",
   "metadata": {},
   "source": [
    "#### Create movie lookup tables\n",
    "Get what given user has rated highly, and what is being recommended"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bade5a50-4525-405a-ae40-ec4fa06e6b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! wget https://files.grouplens.org/datasets/movielens/ml-100k/u.item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7621c74c-64d4-4d73-a083-53ee4c9a6fd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick sidetour - create movie lookup dictionary\n",
    "movie_names = pd.read_csv('u.item', delimiter='|' , \n",
    "                          encoding='latin-1', \n",
    "                          usecols=(0,1),\n",
    "                          names = ['movie_id', 'title'])\n",
    "movielookup = movie_names.to_dict()['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c25fa63d-83d6-44d1-a60e-c67291771473",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for i, watched_movie in enumerate(ratings.filter(lambda x: x['user_id']==USER)):\n",
    "    if i >= 10: #limit to top n\n",
    "        break\n",
    "    else:\n",
    "        key = watched_movie['movie_id'].numpy()\n",
    "        print(f\"\"\"Movies watched: \\n \n",
    "              {i}: {movielookup[key]}\"\"\"\n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a7cb350-eb73-4e0a-aa9f-18afea2f32b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector = emb_627\n",
    "\n",
    "\n",
    "ann_response = ME_index_endpoint.match(\n",
    "    deployed_index_id='movielens_deployed2', \n",
    "    queries=query_vector, \n",
    "    num_neighbors=NUM_NEIGH\n",
    ")\n",
    "\n",
    "print(\"Recommended movie IDs:\", ann_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b02d9342-5e01-470a-810f-4a862d7a9608",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# look at the recommended movies vs the viewed for that user\n",
    "for i, match in enumerate(ann_response[0]):\n",
    "    key = int(float(match.id))\n",
    "    print(f\"\"\"Movies recommended: \\n \n",
    "          {i}: {movielookup[key]} (distance: {match.distance})\"\"\"\n",
    "         )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e791683-6620-487d-bb2f-b783f6997886",
   "metadata": {},
   "source": [
    "### Cleaning up\n",
    "To clean up all Google Cloud resources used in this project, you can delete the Google Cloud project you used for the tutorial. You can also manually delete resources that you created by running the following code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfac66d7-b56c-4224-b847-fb29eb4fa045",
   "metadata": {},
   "outputs": [],
   "source": [
    "INDEX_RESOURCE_NAME\n",
    "# 7352179168240467968"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89f51e78-943e-43ae-8752-01843d5dd705",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a61ecdd-df77-4939-ab93-2ed43dc8878c",
   "metadata": {},
   "outputs": [],
   "source": [
    "index_endpoint_client.undeploy_index(index_endpoint=INDEX_ENDPOINT_NAME, deployed_index_id=DEPLOYED_INDEX_ID)\n",
    "\n",
    "index_client.delete_index(name=INDEX_RESOURCE_NAME)\n",
    "\n",
    "index_endpoint_client.delete_index_endpoint(name=INDEX_ENDPOINT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8037d03b-dfe6-43de-b2a7-ad01b3d4bf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_resource_name = endpoint.resource_name\n",
    "endpoint_resource_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caae4524-b080-486c-9a9f-16f5f9c21c90",
   "metadata": {},
   "outputs": [],
   "source": [
    "deployment_resource_name = deployment.resource_name\n",
    "deployment_resource_name\n",
    "aiplatform.Endpoint.delete(endpoint, gcp_model)\n",
    "#delete our model endpoints, etc.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41544df3-2341-439f-86a6-533826c6bf96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "tf2-gpu.2-6.m95",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-6:m95"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
